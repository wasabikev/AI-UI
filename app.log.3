2024-03-10 12:55:15,248 - app - ERROR - Exception on /chat [POST]
Traceback (most recent call last):
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask\app.py", line 2190, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask\app.py", line 1486, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask\app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask\app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask_login\utils.py", line 290, in decorated_view
    return current_app.ensure_sync(func)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\app.py", line 511, in chat
    chat_output = get_response_from_model(model, messages, temperature)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\app.py", line 474, in get_response_from_model
    response = client.messages.create(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\anthropic\_utils\_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\anthropic\resources\messages.py", line 658, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\anthropic\_base_client.py", line 1208, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\anthropic\_base_client.py", line 897, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\anthropic\_base_client.py", line 988, in _request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'messages: Unexpected role "system". The Messages API accepts a top-level `system` parameter, not "system" as an input message role.'}}
2024-03-10 12:58:22,637 - app - INFO - Received model: claude-3-opus-20240229
2024-03-10 12:58:22,638 - app - INFO - Received temperature: 0.7
2024-03-10 12:58:25,060 - app - ERROR - Exception on /chat [POST]
Traceback (most recent call last):
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\pydantic\main.py", line 751, in __getattr__
    return pydantic_extra[item]
           ~~~~~~~~~~~~~~^^^^^^
KeyError: 'completion'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask\app.py", line 2190, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask\app.py", line 1486, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask\app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask\app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask_login\utils.py", line 290, in decorated_view
    return current_app.ensure_sync(func)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\app.py", line 512, in chat
    chat_output = get_response_from_model(model, messages, temperature)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\app.py", line 481, in get_response_from_model
    chat_output = response.completion
                  ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\pydantic\main.py", line 753, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
AttributeError: 'Message' object has no attribute 'completion'
2024-03-10 13:01:12,824 - app - INFO - Received model: claude-3-opus-20240229
2024-03-10 13:01:12,825 - app - INFO - Received temperature: 0.7
2024-03-10 13:01:15,035 - app - INFO - Response from model: [ContentBlock(text='Here is a test sentence for you:\n\nThe quick brown fox jumps over the lazy dog.', type='text')]
2024-03-10 13:01:15,036 - app - ERROR - Exception on /chat [POST]
Traceback (most recent call last):
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask\app.py", line 2190, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask\app.py", line 1486, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask\app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask\app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask_login\utils.py", line 290, in decorated_view
    return current_app.ensure_sync(func)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\app.py", line 520, in chat
    conversation = Conversation(history=json.dumps(messages),
                                       ^^^^^^^^^^^^^^^^^^^^
  File "C:\Python311\Lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python311\Lib\json\encoder.py", line 200, in encode
    chunks = self.iterencode(o, _one_shot=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python311\Lib\json\encoder.py", line 258, in iterencode
    return _iterencode(o, 0)
           ^^^^^^^^^^^^^^^^^
  File "C:\Python311\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ContentBlock is not JSON serializable
2024-03-10 13:04:17,817 - app - INFO - Received model: claude-3-opus-20240229
2024-03-10 13:04:17,817 - app - INFO - Received temperature: 0.7
2024-03-10 13:04:22,116 - app - INFO - Response from model: Here is a test sentence for you:

The quick brown fox jumps over the lazy dog.

This sentence is a pangram, meaning it contains all 26 letters of the English alphabet. It is often used as a sample sentence to test fonts, keyboards, displays, and other text-related systems.
2024-03-10 13:04:22,118 - app - INFO - Sending summary request to OpenAI: {'model': 'gpt-3.5-turbo', 'messages': [{'role': 'system', 'content': 'Please create a very short (2-4 words) summary title for the following text:\nYou are helping develop a Flask app. A test sentence please Here is a test sentence for you:\n\nThe quick brown fox jumps over the lazy dog.\n\nThis sentence is a pangram, meaning it contains all 26 letters of the English alphabet. It is often used as a sample sentence to test fonts, keyboards, displays, and other text-related systems.'}], 'max_tokens': 10}
