2024-03-13 19:50:32,932 - app - INFO - Received model: claude-3-opus-20240229
2024-03-13 19:50:32,933 - app - INFO - Received temperature: 0.7
2024-03-13 19:50:32,947 - app - ERROR - Exception on /chat [POST]
Traceback (most recent call last):
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask\app.py", line 2190, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask\app.py", line 1486, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask\app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask\app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask_login\utils.py", line 290, in decorated_view
    return current_app.ensure_sync(func)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\app.py", line 513, in chat
    chat_output = get_response_from_model(model, messages, temperature)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\app.py", line 475, in get_response_from_model
    response = client.messages.create(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\anthropic\_utils\_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
TypeError: Messages.create() got an unexpected keyword argument 'system_prompt'
2024-03-13 20:00:12,504 - app - INFO - Received model: claude-3-opus-20240229
2024-03-13 20:00:12,504 - app - INFO - Received temperature: 0.7
2024-03-13 20:00:12,759 - app - ERROR - Exception on /chat [POST]
Traceback (most recent call last):
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask\app.py", line 2190, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask\app.py", line 1486, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask\app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask\app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask_login\utils.py", line 290, in decorated_view
    return current_app.ensure_sync(func)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\app.py", line 511, in chat
    chat_output = get_response_from_model(model, messages, temperature)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\app.py", line 474, in get_response_from_model
    response = client.messages.create(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\anthropic\_utils\_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\anthropic\resources\messages.py", line 658, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\anthropic\_base_client.py", line 1208, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\anthropic\_base_client.py", line 897, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\anthropic\_base_client.py", line 988, in _request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'messages: Unexpected role "human". Did you mean "user"?'}}
2024-03-13 20:01:08,944 - app - INFO - Received model: claude-3-opus-20240229
2024-03-13 20:01:08,944 - app - INFO - Received temperature: 0.7
2024-03-13 20:01:09,157 - app - ERROR - Exception on /chat [POST]
Traceback (most recent call last):
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask\app.py", line 2190, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask\app.py", line 1486, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask\app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask\app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\flask_login\utils.py", line 290, in decorated_view
    return current_app.ensure_sync(func)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\app.py", line 511, in chat
    chat_output = get_response_from_model(model, messages, temperature)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\app.py", line 474, in get_response_from_model
    response = client.messages.create(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\anthropic\_utils\_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\anthropic\resources\messages.py", line 658, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\anthropic\_base_client.py", line 1208, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\anthropic\_base_client.py", line 897, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "C:\Users\kevina\Documents\~LLMS and AI\chatbot\venv\Lib\site-packages\anthropic\_base_client.py", line 988, in _request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'messages: first message must use the "user" role'}}
2024-03-13 20:07:16,026 - app - INFO - Received model: claude-3-opus-20240229
2024-03-13 20:07:16,026 - app - INFO - Received temperature: 0.7
